{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import splitfolders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img.name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car001.jpg</td>\n",
       "      <td>ر ب ل ١ ٨ ٢ ٧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car002.jpg</td>\n",
       "      <td>ى ن ر ٤ ٦ ٢ ٥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car003.jpg</td>\n",
       "      <td>ع س ط ١ ٣ ٧ ٥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car004.jpg</td>\n",
       "      <td>أ ج س ٤ ١ ٤ ٧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>car005.jpg</td>\n",
       "      <td>ق ج ل ٢ ٧ ٣ ٩</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     img.name           label\n",
       "0  car001.jpg   ر ب ل ١ ٨ ٢ ٧\n",
       "1  car002.jpg  ى ن ر ٤ ٦ ٢ ٥ \n",
       "2  car003.jpg  ع س ط ١ ٣ ٧ ٥ \n",
       "3  car004.jpg   أ ج س ٤ ١ ٤ ٧\n",
       "4  car005.jpg   ق ج ل ٢ ٧ ٣ ٩"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitfolders.ratio(input=\"/car_plates/\", output=\"output\", seed=1337, ratio=(.8, 0.1,0.1))\n",
    "\n",
    "dataset=pd.read_csv(r'/car_plates/PoolLabels.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    car001.jpg\n",
       "1    car002.jpg\n",
       "2    car003.jpg\n",
       "3    car004.jpg\n",
       "4    car005.jpg\n",
       "Name: img.name, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dir='/car_plates/output/train/Pics'\n",
    "test_dir='/car_plates/output/test/Pics'\n",
    "validation_dir='/car_plates/output/val/Pics'\n",
    "images= dataset['img.name']\n",
    "labels=dataset['label']\n",
    "images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# directory = '/car_plates/Pics/'\n",
    "\n",
    "# training_img=[]\n",
    "# y=[]\n",
    "\n",
    "# for i in range(images.__len__()):\n",
    "#     images[i]=directory+images[i]\n",
    "    \n",
    "\n",
    "\n",
    "# for i in range(training_img.__len__()):\n",
    "#     x.append(training_img[i])\n",
    "#     y.append(training_label[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(labels[200])\n",
    "# # plt.figure(figsize = (12,10))\n",
    "# # plt.subplot(1,2,1)\n",
    "# # plt.title('Original image')\n",
    "# img = mpimg.imread(images[200])\n",
    "# print(img)\n",
    "# plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# x_train,x_test,y_train,y_test=train_test_split(training_img,training_label,train_size=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "   \n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    car001.jpg\n",
       "1    car002.jpg\n",
       "2    car003.jpg\n",
       "3    car004.jpg\n",
       "4    car005.jpg\n",
       "Name: img.name, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['img.name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2310 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 587 invalid image filename(s) in x_col=\"img.name\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=dataset,\n",
    "    directory=training_dir,\n",
    "                  x_col='img.name',\n",
    "                  y_col='label',\n",
    "                #   target_size =(300, 300),  # target_size = input image size\n",
    "                  \n",
    "                  class_mode ='raw')\n",
    "\n",
    "# test_generator = test_datagen.flow_from_dataframe(\n",
    "#                     x_test,\n",
    "#                     target_size =(150, 150),\n",
    "#                     batch_size = 20,\n",
    "#                     class_mode ='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.batch_size\n",
    "train_generator.samples\n",
    "train_generator.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img.name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car001.jpg</td>\n",
       "      <td>ر ب ل ١ ٨ ٢ ٧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car002.jpg</td>\n",
       "      <td>ى ن ر ٤ ٦ ٢ ٥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car003.jpg</td>\n",
       "      <td>ع س ط ١ ٣ ٧ ٥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car004.jpg</td>\n",
       "      <td>أ ج س ٤ ١ ٤ ٧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>car005.jpg</td>\n",
       "      <td>ق ج ل ٢ ٧ ٣ ٩</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     img.name           label\n",
       "0  car001.jpg   ر ب ل ١ ٨ ٢ ٧\n",
       "1  car002.jpg  ى ن ر ٤ ٦ ٢ ٥ \n",
       "2  car003.jpg  ع س ط ١ ٣ ٧ ٥ \n",
       "3  car004.jpg   أ ج س ٤ ١ ٤ ٧\n",
       "4  car005.jpg   ق ج ل ٢ ٧ ٣ ٩"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.image_shape\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =tf.keras.models.Sequential([\n",
    " tf.keras.layers.Conv2D(32, (3,3), activation='relu' ,\n",
    " input_shape=(300, 300, 3),padding='same'),\n",
    " tf.keras.layers.MaxPooling2D(2, 2),\n",
    " tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D(2,2),\n",
    " tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D(2,2),\n",
    " tf.keras.layers.Flatten(),\n",
    " tf.keras.layers.Dense(512, activation='relu'),\n",
    " tf.keras.layers.Dense(512, activation='relu'),\n",
    " tf.keras.layers.Dense(7, activation='softmax')  \n",
    " \n",
    "    \n",
    " ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    " optimizer='adam',\n",
    "# RMSprop(lr=0.001)\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ', '4', '٣', '١', 'ك', 'ز', '۳', '٦', 'د', '\\u200d', '۷', '8', '۹', '9', '٥', '٠', '6', 'ه', '1', '۸', '٧', '2', '7', '٩', 'ط', 'ج', 'ا', 'ل', 'س', 'ق', 'ف', '٤', '٢', 'ص', '\\xa0', 'م', 'ي', 'ح', 'ى', 'ر', 'ع', 'و', '٨', '5', 'ب', '۱', '3', 'أ', 'ن', '۲'}\n"
     ]
    }
   ],
   "source": [
    "characters = set(char for label in labels for char in label)\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.preprocessing.string_lookup.StringLookup object at 0x0000025528AC6FE0>\n",
      "['١', '٢', '٣', '٤', '٥', '٦', '٧', '٨', '٩', '٠', 'أ', 'ص', 'ف', 'ل', 'ح', 'س', 'د', 'ي', 'ز', 'ن', 'ك', 'ب', 'ط', 'ا', 'ج', 'ر', 'ى', 'م', 'ق', 'ع', 'ه']\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import StringLookup\n",
    "\n",
    "arabic_num_alph=[\n",
    "    \"١\",\n",
    "            \"٢\",\n",
    "            \"٣\",\n",
    "            \"٤\",\n",
    "            \"٥\",\n",
    "            \"٦\",\n",
    "            \"٧\",\n",
    "            \"٨\",\n",
    "            \"٩\",\n",
    "            \"٠\",\n",
    "            \"أ\",\n",
    "            'ص', 'ف','ل','ح','س', 'د', 'ي', 'ز','ن','ك',\"ب\",'ط', 'ا','ج', 'ر', 'ى', 'م', 'ق','ع', 'ه']\n",
    "\n",
    "\n",
    "\n",
    "char_to_num = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(arabic_num_alph), mask_token=None\n",
    ")\n",
    "\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")\n",
    "\n",
    "print(num_to_char)\n",
    "print(arabic_num_alph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 300, 300, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 150, 150, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 148, 148, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 74, 74, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 72, 72, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 36, 36, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 165888)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               84935168  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,294,663\n",
      "Trainable params: 85,294,663\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 7) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     train_generator,\n\u001b[0;32m      3\u001b[0m     \n\u001b[0;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     )\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\AHMEDM~1\\AppData\\Local\\Temp\\__autograph_generated_filef6tjo91v.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\keras\\backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 7) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    \n",
    "    epochs=20,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "253ae6feff4fd1b8c72e2ad785b88438628b5b076110376ae0f22865de7b119a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
